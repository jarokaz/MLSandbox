{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on a single node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Dense, add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image (InputLayer)              (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 30, 30, 32)   896         image[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 28, 28, 64)   18496       conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 9, 9, 64)     0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 9, 9, 64)     36928       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 9, 9, 64)     36928       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 9, 9, 64)     36928       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 9, 9, 64)     36928       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 9, 9, 64)     0           conv2d_10[0][0]                  \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 9, 9, 64)     0           conv2d_12[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 7, 7, 64)     36928       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          16640       global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           2570        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 223,242\n",
      "Trainable params: 223,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def toy_resnet():\n",
    "    inputs = Input(shape=(32, 32, 3), name='image')\n",
    "    x = Conv2D(32, 3, activation='relu')(inputs)\n",
    "    x = Conv2D(64, 3, activation='relu')(x)\n",
    "    block_1_output = MaxPooling2D(3)(x)\n",
    "    \n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(block_1_output)\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    block_2_output = add([x, block_1_output])\n",
    "    \n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    block_3_output = add([x, block_2_output])\n",
    "    \n",
    "    x = Conv2D(64, 3, activation='relu')(block_3_output)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs, name='toy_resnet')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = toy_resnet()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, 'toy_resnet.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    cifar10_builder = tfds.builder(\"cifar10\")\n",
    "    cifar10_builder.download_and_prepare()\n",
    "    cifar10_train, cifar10_valid = cifar10_builder.as_dataset(split=[tfds.Split.TRAIN, tfds.Split.TEST], as_supervised=True)\n",
    "    \n",
    "    return cifar10_train, cifar10_valid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatasetV1Adapter shapes: ((32, 32, 3), ()), types: (tf.uint8, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = load_data()\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_image)\n",
    "val_dataset = val_dataset.map(preprocess_image)\n",
    "train_dataset = train_dataset.shuffle(4096).batch(32).repeat()\n",
    "val_dataset = val_dataset.batch(32).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DatasetV1Adapter shapes: ((?, 32, 32, 3), (?,)), types: (tf.float32, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 1.2661 - sparse_categorical_accuracy: 0.5481 - val_loss: 1.0766 - val_sparse_categorical_accuracy: 0.6158\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.0926 - sparse_categorical_accuracy: 0.6158 - val_loss: 1.1486 - val_sparse_categorical_accuracy: 0.5874\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.9877 - sparse_categorical_accuracy: 0.6552 - val_loss: 0.8918 - val_sparse_categorical_accuracy: 0.6816\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.9142 - sparse_categorical_accuracy: 0.6847 - val_loss: 0.8478 - val_sparse_categorical_accuracy: 0.7027\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.8652 - sparse_categorical_accuracy: 0.7046 - val_loss: 0.8448 - val_sparse_categorical_accuracy: 0.7144\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.8366 - sparse_categorical_accuracy: 0.7203 - val_loss: 0.8421 - val_sparse_categorical_accuracy: 0.7064\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.8145 - sparse_categorical_accuracy: 0.7288 - val_loss: 1.0704 - val_sparse_categorical_accuracy: 0.6665\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.8086 - sparse_categorical_accuracy: 0.7330 - val_loss: 0.8019 - val_sparse_categorical_accuracy: 0.7351\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.8179 - sparse_categorical_accuracy: 0.7322 - val_loss: 1.0907 - val_sparse_categorical_accuracy: 0.6750\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.8159 - sparse_categorical_accuracy: 0.7380 - val_loss: 0.8093 - val_sparse_categorical_accuracy: 0.7469\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.8417 - sparse_categorical_accuracy: 0.7327 - val_loss: 0.8784 - val_sparse_categorical_accuracy: 0.7180\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.8606 - sparse_categorical_accuracy: 0.7279 - val_loss: 0.9941 - val_sparse_categorical_accuracy: 0.7217\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.8697 - sparse_categorical_accuracy: 0.7285 - val_loss: 0.9906 - val_sparse_categorical_accuracy: 0.7032\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.9115 - sparse_categorical_accuracy: 0.7153 - val_loss: 0.9000 - val_sparse_categorical_accuracy: 0.7398\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.9436 - sparse_categorical_accuracy: 0.7127 - val_loss: 1.1435 - val_sparse_categorical_accuracy: 0.7119\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.9803 - sparse_categorical_accuracy: 0.7043 - val_loss: 0.8457 - val_sparse_categorical_accuracy: 0.7404\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 1.0063 - sparse_categorical_accuracy: 0.6985 - val_loss: 1.1858 - val_sparse_categorical_accuracy: 0.7133\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 1.0524 - sparse_categorical_accuracy: 0.6938 - val_loss: 1.1876 - val_sparse_categorical_accuracy: 0.6106\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 1.1284 - sparse_categorical_accuracy: 0.6727 - val_loss: 1.1668 - val_sparse_categorical_accuracy: 0.6888\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 1.2024 - sparse_categorical_accuracy: 0.6507 - val_loss: 1.1133 - val_sparse_categorical_accuracy: 0.6670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8c4d4b8630>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(1e-3),\n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "             metrics=[\"sparse_categorical_accuracy\"]\n",
    "             )\n",
    "\n",
    "model.fit(train_dataset,\n",
    "         epochs=20,\n",
    "         steps_per_epoch=1000,\n",
    "         validation_data=val_dataset,\n",
    "         validation_steps=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_FOLDER = './training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir $SCRIPT_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch $SCRIPT_FOLDER/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./training/training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $SCRIPT_FOLDER/training.py\n",
    "\n",
    "from absl import flags\n",
    "from absl import app\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Dense, add\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "IMAGE_SHAPE = (32, 32, 3)\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "def toy_resnet_model():\n",
    "    inputs = Input(shape=IMAGE_SHAPE, name='image')\n",
    "    x = Conv2D(32, 3, activation='relu')(inputs)\n",
    "    x = Conv2D(64, 3, activation='relu')(x)\n",
    "    block_1_output = MaxPooling2D(3)(x)\n",
    "    \n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(block_1_output)\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    block_2_output = add([x, block_1_output])\n",
    "    \n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    block_3_output = add([x, block_2_output])\n",
    "    \n",
    "    x = Conv2D(64, 3, activation='relu')(block_3_output)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs, name='toy_resnet')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def prepare_datasets():\n",
    "    def _parse_record(example_proto):\n",
    "        features = {\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64, default_value=0)\n",
    "        }\n",
    "        \n",
    "        parsed_features = tf.parse_single_example(example_proto, features)\n",
    "        image = parsed_features['image']\n",
    "        label = parsed_features['label']\n",
    "        \n",
    "        image = tf.image.decode_png(image, channels=3)\n",
    "        #image = tf.cast(image, tf.float32)\n",
    "        #image = image / 255\n",
    "        #image = tf.reshape(image, IMAGE_SHAPE)\n",
    "        \n",
    "        #label = tf.one_hot(label, NUM_CLASSES)\n",
    "        \n",
    "        #return image, label\n",
    "        return image, label\n",
    "\n",
    "    training_images = [os.path.join(FLAGS.training_images, file) for file in os.listdir(FLAGS.training_images)]\n",
    "    validation_images = [os.path.join(FLAGS.validation_images, file) for file in os.listdir(FLAGS.validation_images)]\n",
    "    \n",
    "    train_dataset = tf.data.TFRecordDataset(training_images)\n",
    "    val_dataset = tf.data.TFRecordDataset(validation_images)\n",
    "    \n",
    "    train_dataset = train_dataset.map(_parse_record)\n",
    "    val_dataset = val_dataset.map(_parse_record)\n",
    "    \n",
    "    train_dataset = train_dataset.shuffle(4096).batch(FLAGS.batch_size).repeat()\n",
    "    val_dataset = val_dataset.batch(FLAGS.batch_size).repeat()\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "def train_evaluate():\n",
    "    \n",
    "    train_dataset, val_dataset = prepare_datasets()\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(1e-3),\n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "             metrics=[\"sparse_categorical_accuracy\"]\n",
    "             )\n",
    "\n",
    "    model.fit(train_dataset,\n",
    "         epochs=20,\n",
    "         steps_per_epoch=1000,\n",
    "         validation_data=val_dataset,\n",
    "         validation_steps=200)\n",
    "    \n",
    "    \n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string(\"training_images\", None, \"Training images\")\n",
    "flags.DEFINE_string(\"validation_images\", None, \"Validation images\")\n",
    "flags.DEFINE_integer(\"epochs\", 10, \"Number of epochs to train\")\n",
    "flags.DEFINE_integer(\"batch_size\", 1, \"Batch size\")\n",
    "\n",
    "# Required flags\n",
    "flags.mark_flag_as_required(\"training_images\")\n",
    "flags.mark_flag_as_required(\"validation_images\")\n",
    "\n",
    "def main(argv):\n",
    "    del argv #Unused\n",
    "    \n",
    "    print(FLAGS.training_images)\n",
    "    print(FLAGS.validation_images)\n",
    "    \n",
    "    train, val = prepare_datasets()\n",
    "    \n",
    "    for record in train.take(1):\n",
    "        print(record)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    app.run(main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
