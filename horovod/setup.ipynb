{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on a single node\n",
    "\n",
    "## Prepare a training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_FOLDER = './train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir $SCRIPT_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch $SCRIPT_FOLDER/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./train/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $SCRIPT_FOLDER/train.py\n",
    "\n",
    "from absl import flags\n",
    "from absl import app\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Dense, add\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "IMAGE_SHAPE = (32, 32, 3)\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "def toy_resnet_model():\n",
    "    inputs = Input(shape=IMAGE_SHAPE, name='image')\n",
    "    x = Conv2D(32, 3, activation='relu')(inputs)\n",
    "    x = Conv2D(64, 3, activation='relu')(x)\n",
    "    block_1_output = MaxPooling2D(3)(x)\n",
    "    \n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(block_1_output)\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    block_2_output = add([x, block_1_output])\n",
    "    \n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    block_3_output = add([x, block_2_output])\n",
    "    \n",
    "    x = Conv2D(64, 3, activation='relu')(block_3_output)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs, name='toy_resnet')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def prepare_datasets():\n",
    "    def _parse_record(example_proto):\n",
    "        features = {\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64, default_value=0)\n",
    "        }\n",
    "        \n",
    "        parsed_features = tf.parse_single_example(example_proto, features)\n",
    "        image = parsed_features['image']\n",
    "        label = parsed_features['label']\n",
    "        \n",
    "        image = tf.image.decode_png(image, channels=3)\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = image / 255\n",
    "        \n",
    "        label = tf.one_hot(label, NUM_CLASSES)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    \n",
    "    train_dataset = tf.data.TFRecordDataset(FLAGS.train_files)\n",
    "    eval_dataset = tf.data.TFRecordDataset(FLAGS.eval_files)\n",
    "    \n",
    "    train_dataset = train_dataset.map(_parse_record)\n",
    "    eval_dataset = eval_dataset.map(_parse_record)\n",
    "    \n",
    "    train_dataset = train_dataset.shuffle(4096).batch(FLAGS.batch_size).repeat()\n",
    "    eval_dataset = eval_dataset.batch(FLAGS.batch_size).repeat()\n",
    "    \n",
    "    return train_dataset, eval_dataset\n",
    "\n",
    "\n",
    "def train_evaluate():\n",
    "    \n",
    "    train_dataset, eval_dataset = prepare_datasets()\n",
    "    \n",
    "    model = toy_resnet_model()\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(1e-3),\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"]\n",
    "             )\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=FLAGS['job-dir'].value, update_freq='epoch')\n",
    "    ]\n",
    "    \n",
    "    model.fit(train_dataset,\n",
    "         epochs=FLAGS.epochs,\n",
    "         steps_per_epoch=1000,\n",
    "         callbacks=callbacks,\n",
    "         validation_data=eval_dataset,\n",
    "         validation_steps=200)\n",
    "    \n",
    "    \n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_list(\"train_files\", None, \"Training TFRecord files\")\n",
    "flags.DEFINE_list(\"eval_files\", None, \"Evaluation TFRecord files\")\n",
    "\n",
    "flags.DEFINE_integer(\"epochs\", 5, \"Number of epochs to train\")\n",
    "flags.DEFINE_integer(\"batch_size\", 32, \"Batch size\")\n",
    "flags.DEFINE_integer(\"steps_per_epoch\", 1000, \"Steps per epoch\")\n",
    "flags.DEFINE_integer(\"validation_steps\", 20, \"Batch size\")\n",
    "\n",
    "flags.DEFINE_string(\"job-dir\", None, \"Job dir\")\n",
    "\n",
    "# Required flags\n",
    "flags.mark_flag_as_required(\"train_files\")\n",
    "flags.mark_flag_as_required(\"eval_files\")\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    del argv #Unused\n",
    "    \n",
    "    train_evaluate()\n",
    "     \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    app.run(main)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training script locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = 'gs://jkdatasets/cifar10/cifar10-train.tfrecord-00000-of-00010,gs://jkdatasets/cifar10/cifar10-train.tfrecord-00001-of-00010'\n",
    "EVAL_DATA = 'gs://jkdatasets/cifar10/cifar10-test.tfrecord-00000-of-00001'\n",
    "BUCKET_NAME = 'gs://jkcmle/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a timestamped job name\n",
    "JOB_NAME = \"toyresnet_{}\".format(int(time.time()))\n",
    "JOB_DIR = BUCKET_NAME + JOB_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ml-engine local train \\\n",
    "--module-name train.train \\\n",
    "--package-path train \\\n",
    "--job-dir $JOB_DIR \\\n",
    "-- \\\n",
    "--train_files $TRAIN_DATA \\\n",
    "--eval_files $EVAL_DATA \\\n",
    "--epochs 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training script on CMLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [toyresnet_20190331_161436] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe toyresnet_20190331_161436\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs toyresnet_20190331_161436\n",
      "jobId: toyresnet_20190331_161436\n",
      "state: QUEUED\n"
     ]
    }
   ],
   "source": [
    "# Define a timestamped job name\n",
    "JOB_NAME = \"toyresnet_\" + datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "JOB_DIR = BUCKET_NAME + JOB_NAME\n",
    "REGION = 'us-west1'\n",
    "\n",
    "!gcloud ml-engine jobs submit training $JOB_NAME \\\n",
    "--module-name train.train \\\n",
    "--package-path train \\\n",
    "--runtime-version 1.13 \\\n",
    "--python-version 3.5 \\\n",
    "--region $REGION \\\n",
    "--scale-tier basic-gpu \\\n",
    "--job-dir $JOB_DIR \\\n",
    "-- \\\n",
    "--train_files $TRAIN_DATA \\\n",
    "--eval_files $EVAL_DATA \\\n",
    "--epochs 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training script in a container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "export REGION=us-west1\n",
    "export BUCKET_NAME=gs://jkcmle\n",
    "export PROJECT_ID=$(gcloud config list project --format \"value(core.project)\")\n",
    "export IMAGE_REPO_NAME=toyresnet\n",
    "export IMAGE_TAG=gpu\n",
    "export IMAGE_URI=gcr.io/$PROJECT_ID/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "export TRAIN_DATA=gs://jkdatasets/cifar10/cifar10-train.tfrecord-00000-of-00010,gs://jkdatasets/cifar10/cifar10-train.tfrecord-00001-of-00010\n",
    "export EVAL_DATA=gs://jkdatasets/cifar10/cifar10-test.tfrecord-00000-of-00001\n",
    "export JOB_NAME=J$(date +'%Y%M%d_%H%M%S')\n",
    "export JOB_DIR=$BUCKET_NAME/jobs/$JOB_NAME\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION='us-west1'\n",
    "BUCKET_NAME='gs://jkcmle'\n",
    "PROJECT_ID='sandbox-235500'\n",
    "IMAGE_REPO_NAME='toyresnet'\n",
    "IMAGE_TAG='gpu'\n",
    "IMAGE_URI='gcr.io/' + PROJECT_ID + '/' + IMAGE_REPO_NAME + ':' + IMAGE_TAG\n",
    "TRAIN_DATA='gs://jkdatasets/cifar10/cifar10-train.tfrecord-00000-of-00010,gs://jkdatasets/cifar10/cifar10-train.tfrecord-00001-of-00010'\n",
    "EVAL_DATA='gs://jkdatasets/cifar10/cifar10-test.tfrecord-00000-of-00001'\n",
    "JOB_NAME = 'toyresnet_' + datetime.datetime.today().strftime('%Y%M%d_%H%M%S')\n",
    "JOB_DIR=BUCKET_NAME + '/jobs/' + JOB_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/sandbox-235500toyresnet:gpu'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [toyresnet_20193001_203049] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe toyresnet_20193001_203049\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs toyresnet_20193001_203049\n",
      "jobId: toyresnet_20193001_203049\n",
      "state: QUEUED\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ml-engine jobs submit training $JOB_NAME \\\n",
    "--region $REGION \\\n",
    "--master-image-uri $IMAGE_URI \\\n",
    "--scale-tier BASIC_GPU \\\n",
    "-- \\\n",
    "--train_files $TRAIN_DATA \\\n",
    "--eval_files $EVAL_DATA \\\n",
    "--epochs 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-01 20:30:57.938311: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-04-01 20:31:01.848627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-04-01 20:31:01.849169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
      "2019-04-01 20:31:01.914276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-04-01 20:31:01.914848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:05.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
      "2019-04-01 20:31:01.914928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\n",
      "2019-04-01 20:31:02.579578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-04-01 20:31:02.579647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 \n",
      "2019-04-01 20:31:02.579657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N N \n",
      "2019-04-01 20:31:02.579663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   N N \n",
      "2019-04-01 20:31:02.580269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10759 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "2019-04-01 20:31:02.580899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10759 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7)\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 1.8542 - acc: 0.2867 - val_loss: 1.6169 - val_acc: 0.3955\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 1.4243 - acc: 0.4792 - val_loss: 1.3357 - val_acc: 0.5083\n"
     ]
    }
   ],
   "source": [
    "!docker run --rm --runtime=nvidia $IMAGE_URI \\\n",
    "--train_files=$TRAIN_DATA \\\n",
    "--eval_files=$EVAL_DATA \\\n",
    "--epochs=2 \\\n",
    "--job-dir=$JOB_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
